{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make sure you downloand anaconda\n",
    "[download anaconda](https://www.continuum.io/downloads)\n",
    "1. Anaconda is the best data science python distribution. It comes with 100's of 3rd party libraries for all sorts of machine learning\n",
    "2. You get the excellent jupyter notebook where this material is being produced. Start in command prompt with **jupyter notebook**\n",
    "3. Download new packages with **conda install packagename**\n",
    "4. There is more to jupyter notebook - a lot more - http://jupyter.org/, http://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/what_is_jupyter.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Google\n",
    "Usually, a simple get request from the python **requests** libray is all it takes to retrieve the underlying html from a website, for currently unknown reasons this does not work at all for search requests. \n",
    "\n",
    "Because of this, a [third party software GoogleScraper](https://github.com/NikolaiT/GoogleScraper) is used from the command prompt that yields very nice meta-data on google scraped results. There are many options that you can use to get the desired result. Read the docs for more info.\n",
    "\n",
    "### What does the GoogleScraper command below return?\n",
    "1. json data of the first 10 pages of Google search results with 50 results per page for a total of 500 items\n",
    "2. It specifically search quora for any appearance of the word \"should\"\n",
    "3. The only real meta-data we are after is the url of the result. But there are several other items returned (see Below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2016-06-28 01:07:25,825 - GoogleScraper.caching - INFO - 10 cache files found in .scrapecache/',\n",
       " '2016-06-28 01:07:25,825 - GoogleScraper.caching - INFO - 10/10 objects have been read from the cache. 0 remain to get scraped.']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "************** This is a python string but can be thought of as a comment ***********\n",
    "\n",
    "Run the command inside of ipython notebook! Very cool feature\n",
    "'''\n",
    "%system GoogleScraper -m http -p 10 -n 50 -q \"should site:quora.com\" --output-filename quora_june.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open the file\n",
    "We saved the above results into a file **quora_june.json**. We open it up and use the json library to load it into a python list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"quora_june.json\", 'r') as f:\n",
    "    data  = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "What type is our object?\n",
    "'''\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "How many items in the list?\n",
    "'''\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Lets inspect the first item and see what type it is\n",
    "'''\n",
    "first = data[0]\n",
    "type(first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['num_results', 'page_number', 'results', 'num_results_for_query', 'effective_query', 'status', 'requested_by', 'search_engine_name', 'requested_at', 'no_results', 'id', 'query', 'scrape_method'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Since we have a dictionary, lets see the keys to the dict\n",
    "'''\n",
    "first.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('should site:quora.com', '1', 'About 1,800,000 results (0.52 seconds)\\xa0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "lets look at some of the values of these keys\n",
    "'''\n",
    "first['query'], first['id'], first['num_results_for_query']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Some further investigation, leads to see that the actual results are in the 'resutls key'\n",
    "'''\n",
    "first_results = first['results']\n",
    "type(first_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(first_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(first_results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'domain': 'www.quora.com',\n",
       " 'id': '1',\n",
       " 'link': 'https://www.quora.com/Why-should-I-vote-for-Bernie-Sanders',\n",
       " 'link_type': 'results',\n",
       " 'rank': '1',\n",
       " 'serp_id': '1',\n",
       " 'snippet': 'Why should the upper class vote for Bernie Sanders?  What are some reasons to not vote for Bernie Sanders?  Why would, or should, a Republican vote for Bernie Sanders?',\n",
       " 'title': 'Why should I vote for Bernie Sanders? - Quora',\n",
       " 'visible_link': 'https://www.quora.com/Why-should-I-vote-for-Bernie-Sanders'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "An example result\n",
    "'''\n",
    "first_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Looks like the results key has a list of length 50\n",
    "Each item in the list is a python dictionary of the all important metadata\n",
    "Lets put all this data into one list. A list of python dictionaries\n",
    "'''\n",
    "\n",
    "all_results = []\n",
    "for d in data:\n",
    "    all_results.extend(d['results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "We should have 500 pieces of metadata\n",
    "'''\n",
    "len(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'domain': 'www.quora.com',\n",
       " 'id': '251',\n",
       " 'link': 'https://www.quora.com/Laundry-How-should-you-wash-clothes',\n",
       " 'link_type': 'results',\n",
       " 'rank': '1',\n",
       " 'serp_id': '6',\n",
       " 'snippet': 'Keep in mind that warmer water increases the possibility of dye bleeding, so whites and light colors should always be washed separately from bright or dark\\xa0...',\n",
       " 'title': 'Laundry: How should you wash clothes? - Quora',\n",
       " 'visible_link': 'https://www.quora.com/Laundry-How-should-you-wash-clothes'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Success! We have 500 pieces of metadata, each containing a different search result\n",
    "Like take a look at the 101st one\n",
    "'''\n",
    "sample_result = all_results[100]\n",
    "sample_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.quora.com/Laundry-How-should-you-wash-clothes'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Looks like the url is in the 'link' key of the meta data. Lets look at it by itself\n",
    "'''\n",
    "link = sample_result['link']\n",
    "link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspecting html\n",
    "Now that we know how to access each link from GoogleScraper, we will manually inspect the page in order to find the question and some other meta data associated with that page. We can now use the requests library to get the html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This command, issues a get request and returns a 'response' object\n",
    "'''\n",
    "response = requests.get(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "The 'text' attribute of the response object contains the actual text of the html when you inspect it with \n",
    "your browser's developers tools\n",
    "\n",
    "BeautifulSoup is a python library that parses the gigantic mess of html code underneath\n",
    "'''\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "After manually inspecting the page, it looks like the question is going to always be\n",
    "in a div with class \"QuestionArea\". This is of course subject to change but generally should be stable\n",
    "\n",
    "The actually text of the question is in a class called \"rendered_qtext\"\n",
    "'''\n",
    "question_area = soup.find(\"div\", { \"class\" : \"QuestionArea\" })\n",
    "question_text = question_area.find(\"span\", {\"class\": \"rendered_qtext\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'question_span' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-2c17362a4867>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mLets\u001b[0m \u001b[0mtake\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlook\u001b[0m \u001b[0mat\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mVariable\u001b[0m \u001b[0mquestion_span\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mstill\u001b[0m \u001b[0ma\u001b[0m \u001b[0mBeautifulSoup\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m '''\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mquestion_span\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'question_span' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Lets take a look at the text. Variable question_span is still a BeautifulSoup object\n",
    "'''\n",
    "question_span.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requests library is not enough :(\n",
    "After some more work not shown here, it was discovered that the requests library does not use your google profile information to login. Logging in to google is very important as this gives acccess to the number of followers of a question.\n",
    "\n",
    "# Use selenium to manipulate page\n",
    "selenium is a third party python library that lets you manipulate a webpage. A chrome driver had to be downloaded first (so this part won't work in your local notebook without downloading it yourself and changing the path). A new username and password dedicated just for scraping quora was created by phu. \n",
    "\n",
    "The code below might not work on your machine because it did ask me (teddy in houston) where the user normally logs in from. But after I entered that info in, the code below shold work every time.\n",
    "\n",
    "It sleeps for 3 seconds between entering username and password to make sure it has time to get to the password page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Selenium manually logs into google. Beforehand I created a quora account with the gmail email below.\n",
    "\n",
    "A new window should pop-up and you can actually see the magic happen before your eyes.\n",
    "\n",
    "Eventually chrome will navigate to the \"link\" variable above (look up several cells)\n",
    "'''\n",
    "driver_location = \"./chromedriver\"\n",
    "driver = webdriver.Chrome(executable_path=driver_location)\n",
    "driver.get(\"http://www.google.com\")\n",
    "driver.find_element_by_class_name('gb_Me').click()\n",
    "inputElement = driver.find_element_by_id(\"Email\")\n",
    "inputElement.send_keys('bsmithfun2016@gmail.com')\n",
    "inputElement.send_keys(Keys.ENTER)\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "inputElement = driver.find_element_by_id(\"Passwd\")\n",
    "inputElement.send_keys('qwerty123!!!')\n",
    "inputElement.send_keys(Keys.ENTER)\n",
    "driver.get(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'40'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Now lets get that follows number\n",
    "'''\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "follows_num = soup.find('span', {'class', 'count'}).text\n",
    "follows_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Success! Now lets automate this!\n",
    "The below code automatically navigates to each of the 500 quora links to grab 3 items\n",
    "1. The question\n",
    "2. The number of followers\n",
    "3. The number of answers\n",
    "\n",
    "It keeps everything in text - we will handle number of followers that return '5.4k' later\n",
    "\n",
    "**We might want to think about sleeping for a couple seconds between each iteration so quora doesn't boot us**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This takes about 1 - 2 seconds per iteration\n",
    "\n",
    "It looks like a small bug creeps up here if the url is not formatted correctly.\n",
    "This just happened when one of the url had some junk in front of it ('/url?url=')\n",
    "I'll fix this later\n",
    "'''\n",
    "questions = []\n",
    "for result in all_results:\n",
    "    link = result['link']\n",
    "    driver.get(link)\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    question_area = soup.find(\"div\", { \"class\" : \"QuestionArea\" })\n",
    "    question_span = question_area.find(\"span\", {\"class\": \"rendered_qtext\"})\n",
    "    answers = soup.find(\"div\", {\"class\", \"QuestionPageAnswerHeader\"})\n",
    "    answers_num = answers.text.split()[0]\n",
    "    follows_num = soup.find('span', {'class', 'count'}).text\n",
    "    questions.append([question_span.text, follows_num, answers_num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pandas - easy data manipulation\n",
    "pandas is an awesome 3rd party library that makes data manipulation a breeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "use pandas main object the DataFrame to insert all the data and insepct the top 20 rows\n",
    "'''\n",
    "df_questions = pd.DataFrame(questions, columns=['Question', 'Follows', 'Answers'])\n",
    "df_questions.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert strings to ints\n",
    "This could have been done in the loop above, but I wanted to inspect the data first. Lets take a look at the last character of the follows column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Look at frequency of occurence of last character in follows column\n",
    "'''\n",
    "df_questions['Follows'].str.get(-1).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "They are all numbers except for 'k'\n",
    "\n",
    "This line might be hard to follow but basically...\n",
    "it multiplies the number by 1000 if it ends in k else just makes it an int\n",
    "and reassigns it to the same column\n",
    "'''\n",
    "df_questions['Follows'] = df_questions['Follows'].map(lambda x: int(float(x[:-1]) * 1000) if x[-1] == 'k' else int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Lets do same thing for Answers column\n",
    "'''\n",
    "df_questions['Answers'].str.get(-1).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Just the + sign is the only non-numeric\n",
    "\n",
    "Lets take a look at those\n",
    "'''\n",
    "df_questions[df_questions['Answers'].map(lambda x: '+' in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Looks like number of answres stops at 100\n",
    "\n",
    "Make conversion\n",
    "'''\n",
    "df_questions['Answers'] = df_questions['Answers'].map(lambda x: 100 if '+' in x else int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Inspect data after transformation\n",
    "'''\n",
    "df_questions.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Sort by most follows\n",
    "'''\n",
    "pd.options.display.max_colwidth = 150\n",
    "df_questions.sort_values('Follows', ascending=False, inplace=True)\n",
    "df_questions.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Convert to csv\n",
    "'''\n",
    "df_questions.to_csv('questions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
